{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuru/anaconda3/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def dcg(r):\n",
    "    r = np.asfarray(r)[:10]\n",
    "    if r.size:\n",
    "        return r[0] + np.sum(r[1:] / np.log2(np.arange(2, r.size + 1)))\n",
    "    return 0.\n",
    "\n",
    "def ndcg(r):\n",
    "    dcg_max = dcg(sorted(r, reverse=True))\n",
    "    if not dcg_max:        \n",
    "        return 1.\n",
    "    return dcg(r) / dcg_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_ndcg(X):\n",
    "    ndcgs = []\n",
    "    query_ids = np.unique(X['query_id'])\n",
    "    for item in query_ids:\n",
    "        ndcgs.append(ndcg(X[X['query_id'] == item]['relevance'].values))\n",
    "    ndcgs = np.array(ndcgs)\n",
    "    return np.mean(ndcgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_cross_val_score(X, algorithm, features, cv=5):\n",
    "    query_ids = np.unique(X['query_id'])\n",
    "    kf = KFold(n_splits=cv)\n",
    "    kf.get_n_splits(query_ids)\n",
    "    ndcgs = []\n",
    "    for train_ind, test_ind in kf.split(query_ids):\n",
    "        X_train = X[X['query_id'].isin(train_ind)]\n",
    "        X_test = X[X['query_id'].isin(test_ind)]\n",
    "        \n",
    "        \n",
    "        algorithm.fit(X_train[features].values, X_train['relevance'].values)\n",
    "        \n",
    "        X_test = X_test.copy()\n",
    "        \n",
    "        X_test['predicted_relevance'] = algorithm.predict(X_test[features].values)\n",
    "        \n",
    "        ndcgs.append(calculate_ndcg(X_test.sort_values(['query_id', 'predicted_relevance'], \n",
    "                                                       ascending=[True, False])))\n",
    "    return np.array(ndcgs), np.mean(np.array(ndcgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_pool = pd.read_csv('data/train.csv', encoding='utf-8')\n",
    "test_pool = pd.read_csv('data/test.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Напишем функции, генерирующие простые признаки основанные на пересечении триграмм между запросом и названием организации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_trigrams(string):\n",
    "    string = '^^' + string + '$$'\n",
    "    trigrams = set()\n",
    "    trigrams_count = 0\n",
    "    \n",
    "    for i in range(len(string) - 2):\n",
    "        trigrams.add(string[i:i+3])\n",
    "        trigrams_count += 1\n",
    "        \n",
    "    return trigrams, trigrams_count\n",
    "\n",
    "def common_trigrams_factors(query, org_name):\n",
    "    query_trigrams, query_trigrams_count = get_trigrams(query)\n",
    "    org_name_trigrams, org_name_trigrams_count = get_trigrams(org_name)\n",
    "\n",
    "    factors = [float(len(query_trigrams.intersection(org_name_trigrams)))]\n",
    "\n",
    "    factors.append(0. if query_trigrams_count == 0. else 0.1 + factors[0] / query_trigrams_count)\n",
    "    factors.append(0. if org_name_trigrams_count == 0. else 0.1 + factors[0] / org_name_trigrams_count)    \n",
    "    \n",
    "    return factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем данные факторы для каждого файла"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Достанем информацию о координатах объекта и всё запихаем куда надо."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_pos_and_coordinate(t):\n",
    "    return t['pos']['coordinates']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_org_information = pd.read_json('data/train_org_information.json', orient='columns', \n",
    "                                     convert_dates=False, convert_axes=False)\n",
    "train_org_information = train_org_information.transpose()\n",
    "\n",
    "train_address = train_org_information['address'].apply(get_pos_and_coordinate).to_frame()\n",
    "train_address['org_id'] = train_address.index\n",
    "train_address[['org_id']] = train_address[['org_id']].apply(pd.to_numeric)\n",
    "train_pool = pd.merge(train_pool, train_address, left_on='org_id', right_on='org_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_org_information = pd.read_json('data/test_org_information.json', orient='columns', \n",
    "                                     convert_dates=False, convert_axes=False)\n",
    "test_org_information = test_org_information.transpose()\n",
    "\n",
    "test_address = test_org_information['address'].apply(get_pos_and_coordinate).to_frame()\n",
    "test_address['org_id'] = test_address.index\n",
    "test_address[['org_id']] = test_address[['org_id']].apply(pd.to_numeric)\n",
    "test_pool = pd.merge(test_pool, test_address, left_on='org_id', right_on='org_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_and_take_first(string):\n",
    "    answer = string.split(',')\n",
    "    return float(answer[0])\n",
    "\n",
    "def split_and_take_second(string):\n",
    "    answer = string.split(',')\n",
    "    return float(answer[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_pool['window_x'] = train_pool['window_center'].apply(split_and_take_first)\n",
    "train_pool['window_y'] = train_pool['window_center'].apply(split_and_take_second)\n",
    "train_pool['org_x'] = train_pool['address'].apply(lambda x: x[0])\n",
    "train_pool['org_y'] = train_pool['address'].apply(lambda x: x[1])\n",
    "train_pool['rel_x'] = np.absolute(train_pool['org_x'] - train_pool['window_x'])\n",
    "train_pool['rel_y'] = np.absolute(train_pool['org_y'] - train_pool['window_y'])\n",
    "train_pool['size_x'] = train_pool['window_size'].apply(split_and_take_first)\n",
    "train_pool['size_y'] = train_pool['window_size'].apply(split_and_take_second)\n",
    "train_pool['rel/size_x'] = train_pool['rel_x'] / train_pool['size_x']\n",
    "train_pool['rel/size_y'] = train_pool['rel_y'] / train_pool['size_y']\n",
    "train_pool['distance'] = (train_pool['rel_x'] ** 2 + train_pool['rel_y'] ** 2) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_pool['window_x'] = test_pool['window_center'].apply(split_and_take_first)\n",
    "test_pool['window_y'] = test_pool['window_center'].apply(split_and_take_second)\n",
    "test_pool['org_x'] = test_pool['address'].apply(lambda x: x[0])\n",
    "test_pool['org_y'] = test_pool['address'].apply(lambda x: x[1])\n",
    "test_pool['rel_x'] = np.absolute(test_pool['org_x'] - test_pool['window_x'])\n",
    "test_pool['rel_y'] = np.absolute(test_pool['org_y'] - test_pool['window_y'])\n",
    "test_pool['size_x'] = test_pool['window_size'].apply(split_and_take_first)\n",
    "test_pool['size_y'] = test_pool['window_size'].apply(split_and_take_second)\n",
    "test_pool['rel/size_x'] = test_pool['rel_x'] / test_pool['size_x']\n",
    "test_pool['rel/size_y'] = test_pool['rel_y'] / test_pool['size_y']\n",
    "test_pool['distance'] = (test_pool['rel_x'] ** 2 + test_pool['rel_y'] ** 2) ** 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Развлекаемся c триграммами рубрик."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_rubric_information = pd.read_json('data/train_rubric_information.json', orient='columns', \n",
    "                                        convert_dates=False, convert_axes=False).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_rubric_information = pd.read_json('data/test_rubric_information.json', orient='columns', \n",
    "                                        convert_dates=False, convert_axes=False).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_one_string_with_org_descr(names):\n",
    "    good_languages = ['en', 'tr', 'ru', 'uk', 'uz']\n",
    "    answer = '^^'\n",
    "    for item in names:\n",
    "        if item['locale'] in good_languages:\n",
    "            answer += item['value']\n",
    "    answer += '$$'\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_one_string_with_org_descr_ugly(descriptions):\n",
    "    good_languages = ['en', 'tr', 'ru', 'uk', 'uz']\n",
    "    answer = '^^'\n",
    "    for item in descriptions:\n",
    "        item = item['value']\n",
    "        if item['locale'] in good_languages:\n",
    "            answer += item['value']\n",
    "    answer += '$$'\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_rubric_information['concat_names'] = train_rubric_information['names'].apply(\n",
    "    make_one_string_with_org_descr)\n",
    "train_rubric_information['concat_keywords'] = train_rubric_information['keywords'].apply(\n",
    "    make_one_string_with_org_descr)\n",
    "train_rubric_information['concat_phrases'] = train_rubric_information['phrases'].apply(\n",
    "    make_one_string_with_org_descr)\n",
    "train_rubric_information['concat_descriptions'] = train_rubric_information['descriptions'].apply(\n",
    "    make_one_string_with_org_descr_ugly)\n",
    "\n",
    "\n",
    "test_rubric_information['concat_names'] = test_rubric_information['names'].apply(\n",
    "    make_one_string_with_org_descr)\n",
    "test_rubric_information['concat_keywords'] = test_rubric_information['keywords'].apply(\n",
    "    make_one_string_with_org_descr)\n",
    "test_rubric_information['concat_phrases'] = test_rubric_information['phrases'].apply(\n",
    "    make_one_string_with_org_descr)\n",
    "test_rubric_information['concat_descriptions'] = test_rubric_information['descriptions'].apply(\n",
    "    make_one_string_with_org_descr_ugly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_rubric_information.index = pd.to_numeric(train_rubric_information.index)\n",
    "train_rubric_information['rubric_id'] = train_rubric_information.index\n",
    "train_org_information['single_rubric_id'] = train_org_information['rubrics'].apply(lambda x: int(x[0]))\n",
    "\n",
    "train_org_information.index = pd.to_numeric(train_org_information.index)\n",
    "train_org_information['org_id'] = train_org_information.index\n",
    "\n",
    "test_rubric_information.index = pd.to_numeric(test_rubric_information.index)\n",
    "test_rubric_information['rubric_id'] = test_rubric_information.index\n",
    "test_org_information['single_rubric_id'] = test_org_information['rubrics'].apply(lambda x: int(x[0]))\n",
    "\n",
    "test_org_information.index = pd.to_numeric(test_org_information.index)\n",
    "test_org_information['org_id'] = test_org_information.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Триграммы адресов организаций."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_org_information['string_address'] = train_org_information['address'].apply(\n",
    "    lambda x: x['formatted']['value'])\n",
    "test_org_information['string_address'] = test_org_information['address'].apply(\n",
    "    lambda x: x['formatted']['value']).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сольём организации и train_org_info:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_train_pool = pd.merge(train_pool, pd.merge(train_org_information, train_rubric_information, \n",
    "                                               left_on='single_rubric_id', \n",
    "                                               right_on='rubric_id')[['org_id', 'concat_keywords',  \n",
    "                                                                      'concat_phrases', 'concat_descriptions', \n",
    "                                                                      'concat_names', 'string_address']], \n",
    "         left_on='org_id', right_on='org_id')\n",
    "\n",
    "new_test_pool = pd.merge(test_pool, pd.merge(test_org_information, test_rubric_information, \n",
    "                                               left_on='single_rubric_id', \n",
    "                                               right_on='rubric_id')[['org_id', 'concat_keywords',  \n",
    "                                                                      'concat_phrases', 'concat_descriptions', \n",
    "                                                                      'concat_names', 'string_address']], \n",
    "         left_on='org_id', right_on='org_id')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Все триграммы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_all_trigram_factors(row):\n",
    "    trigram_factor_strings = ['org_name', 'concat_keywords', 'concat_phrases', \n",
    "                              'concat_descriptions', 'concat_names', 'string_address']\n",
    "\n",
    "    all_factors = np.empty(0)\n",
    "    for item in trigram_factor_strings:\n",
    "        all_factors = np.append(all_factors, \n",
    "                                np.array(common_trigrams_factors(row.query, row[item])))\n",
    "    return pd.Series(all_factors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_trigram_factors = new_train_pool.apply(calc_all_trigram_factors, axis=1)\n",
    "\n",
    "test_trigram_factors = new_test_pool.apply(calc_all_trigram_factors, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(train_trigram_factors.columns.size):\n",
    "    train_pool['Trig' + str(i)] = train_trigram_factors.values[:, i]\n",
    "    \n",
    "for i in range(test_trigram_factors.columns.size):\n",
    "    test_pool['Trig' + str(i)] = test_trigram_factors.values[:, i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_pool['query_len'] = train_pool['query'].apply(lambda x: int(len(x) > 15))\n",
    "test_pool['query_len'] = test_pool['query'].apply(lambda x: int(len(x) > 15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Отберём фичи для обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = ['size_x', 'size_y', 'rel/size_x', 'rel/size_y', 'distance', 'query_len']\n",
    "for i in range(18):\n",
    "    features.append('Trig' + str(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем кросс-вал-скор."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.81429095,  0.92988094,  0.92578995,  0.93121501,  0.99113647,\n",
       "         0.99859876,  0.93090933,  1.        ,  0.8904111 ,  0.869623  ]),\n",
       " 0.92818555205961017)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_cross_val_score(train_pool, XGBRegressor(n_estimators=500, max_depth=8), features, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_features = test_pool[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_features = train_pool[features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем отхерачить целевую переменную на другие промежутки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_pool['other_relevance'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Экспериметны!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Натравим на все это xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = XGBRegressor(n_estimators=500, max_depth=8)\n",
    "clf.fit(train_features.values , train_pool[['relevance']].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_pool['relevance'] = clf.predict(test_features.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Записываем в файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_pool.sort_values(['query_id', 'relevance'], \n",
    "                      ascending=[True, False])[['query_id', 'org_id']].to_csv('result.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
